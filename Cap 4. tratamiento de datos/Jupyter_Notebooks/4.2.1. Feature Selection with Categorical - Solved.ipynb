{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 5. Fase de tratamiento de datos</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>2.1. Feature Selection con datatos categóricos</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Librerías](#section11)\n",
    "    * [1.2. CSV](#section12)\n",
    "* [2. Prepración de los datos](#section2)\n",
    "    * [2.1. Tipo de las variables](#section21)\n",
    "    * [2.2. División para entrenamiento/validación](#section22)\n",
    "* [3. Transformación de los datos](#section3)\n",
    "    * [3.1. Codificación de train/test](#section31)\n",
    "    * [3.2. Codificación del target](#section32)\n",
    "    * [3.3. Codificación de todos los atributos](#section33)\n",
    "* [4. Feature selection](#section4)\n",
    "    * [4.1. Chi-cuadrada](#section41)\n",
    "    * [4.2. Información Mutua](#section42)    \n",
    "* [5. Fase de modelado](#section5)\n",
    "    * [5.1. Resultados de linea base](#section51)\n",
    "    * [5.2. Resultados con $\\chi^{2}$](#section52) \n",
    "    * [5.3. Resultados con Información Mutua](#section53)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, feature selection, también llamado como selección de mejores características o atributos, es el proceso de seleccionar un subconjunto de características pertinentes (variables, predictores) para su uso en construcción de modelos. Las técnicas de feature selection son utilizadas por cuatro razones:\n",
    "* Simplificación de modelos con el fin de hacerlas más sencillas de interpretar para los usuarios/investigadores.\n",
    "* Menor tiempo de entrenamiento.\n",
    "* Evitar la maldición de la dimensionalidad:\n",
    "* Generalización realzada por reducir _overfitting_ (formalmente, reducción de varianza).\n",
    "\n",
    "En este tutorial, descubrirá cómo realizar la selección de funciones con datos de entrada categóricos:\n",
    "* El problema del modelado predictivo de _Breast Cancer_ con entradas categóricas y _target_ de clasificación binaria.\n",
    "* Cómo evaluar la importancia de las características categóricas utilizando las estadísticas de chi-cuadrado e información mutua.\n",
    "* Cómo realizar la selección de características para datos categóricos al ajustar y evaluar un modelo de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vamos a declarar algunas librerías generales que ya hemos estado trabajando y que usaremos a lo largo de la sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. CSV</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección, el conjunto de datos clasifica los datos de pacientes con cáncer de mama como recurrencia o no recurrencia del cáncer. Hay 286 ejemplos y nueve características de entrada. Es un problema de clasificación binaria.\n",
    "\n",
    "La información sobre este conjunto de datos la encontramos en [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer). Mirando los datos, podemos ver que las nueve variables de entrada son categóricas que están dadas entre comillas simples (**'**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasification problem\n",
    "filename = 'data/breast-cancer.csv'\n",
    "names = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiant', 'class']\n",
    "df_cla = pd.read_csv(filename, names=names)\n",
    "dataset = df_cla.values\n",
    "X_cla = dataset[:, :-1]\n",
    "Y_cla = dataset[:,-1]\n",
    "#Y_cla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Prepración de los datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en primera instancia los pasos que tenemos que realizar para poder trabajar nuestro conjunto de datos, para luego poder aplicarle Feature selection teniendo datos categóricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Tipo de las variables </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tenemos que asegurarnos es que las variables se encuentren en formato _String_ ya que para poder trabajarlo bien. En este conjunto de datos todas las variables se encuentran con datos categóricos. Aunque ya los teníamos como objeto vamos formatearlo de todas maneras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"'40-49'\" \"'premeno'\" \"'15-19'\" ... \"'right'\" \"'left_up'\" \"'no'\"]\n",
      " [\"'50-59'\" \"'ge40'\" \"'15-19'\" ... \"'right'\" \"'central'\" \"'no'\"]\n",
      " [\"'50-59'\" \"'ge40'\" \"'35-39'\" ... \"'left'\" \"'left_low'\" \"'no'\"]\n",
      " ...\n",
      " [\"'30-39'\" \"'premeno'\" \"'30-34'\" ... \"'right'\" \"'right_up'\" \"'no'\"]\n",
      " [\"'50-59'\" \"'premeno'\" \"'15-19'\" ... \"'right'\" \"'left_low'\" \"'no'\"]\n",
      " [\"'50-59'\" \"'ge40'\" \"'40-44'\" ... \"'left'\" \"'right_up'\" \"'no'\"]]\n"
     ]
    }
   ],
   "source": [
    "print(X_cla)\n",
    "# Convertimos todos los campos a String\n",
    "# Además, con este truco podemos \"camuflar\" valores NaN que tenemos y así no nos dará error las conversiones\n",
    "X_cla = X_cla.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. División para entrenamiento/validación </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados, podemos dividir los datos en conjuntos de entrenamiento y validación para que podamos ajustar y evaluar un modelo de aprendizaje. Utilizaremos la función `train_test_split()` y utilizaremos el 67% de los datos para el entrenamiento y el 33% para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (191, 9) (191,)\n",
      "Test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cla, Y_cla, test_size=0.33, random_state=1)\n",
    "# summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Transformación de los datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar la clase `OrdinalEncoder` de scikit-learn para codificar cada variable en enteros. Esta es una clase flexible y permite que el orden de las categorías se especifique como argumentos si se conoce dicho orden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "Más información en la documentación oficial sobre la clase [`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html). \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "## <font color=\"#004D7F\"> 3.1. Codificación de train/test </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función llamada `prepare_inputs()` toma los datos de entrada para entrenamiento y validación y los codifica utilizando una codificación ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "## <font color=\"#004D7F\"> 3.2. Codificación del _target_ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos preparar la variable _target_ (clase). Es un problema de clasificación binaria, por lo que debemos asignar las dos etiquetas de clase a 0 y 1. Este es un tipo de codificación ordinal, y scikit-learn proporciona la clase `LabelEncoder` específicamente diseñada para este propósito. Podríamos usar el `OrdinalEncoder` con la misma facilidad y lograr el mismo resultado, aunque `LabelEncoder` está diseñado para codificar una sola variable.\n",
    "\n",
    "El entero de la función `prepare_targets()` codifica los datos de salida para entrenamiento/validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "Más información en la documentación oficial sobre la clase [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section33\"></a>\n",
    "## <font color=\"#004D7F\"> 3.3. Codificación de todos los atributos </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizadas las funciones, podemos pasar, a cualés corresponda, los diferentes atributos de nuestro conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos cargado y preparado el conjunto de datos, podemos explorar feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Feature selection</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos técnicas populares de selección de características que se pueden usar para datos de entrada categóricos y una variable objetivo categórica (clase):\n",
    "* Prueba estadística Chi-Cuadrada ($\\chi^{2}$).\n",
    "* Prueba estadística de información mutua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section41\"></a>\n",
    "## <font color=\"#004D7F\"> 4.1. Chi-cuadrada</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prueba de hipótesis estadística $\\chi^{2}$ de Pearson es un ejemplo de una prueba de independencia entre variables categóricas. Los resultados de esta prueba se pueden utilizar para la selección de características, donde aquellas características que son independientes de la variable objetivo se pueden eliminar del conjunto de datos.\n",
    "\n",
    "La biblioteca de máquina scikit-learn proporciona una implementación de la prueba de chi-cuadrado en la función `chi2()`. Esta función se puede utilizar en una estrategia de selección de características, como seleccionar las _k_ características más relevantes (valores más grandes) a través de la clase `SelectKBest`.\n",
    "\n",
    "Vamos a definir la clase `SelectKBest` para usar la función `chi2()` y seleccionar todas las características, luego transformar los datos de train/test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "Más información en la documentación oficial sobre la función [`chi2()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html). \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chi-cuadrado\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# feature selection\n",
    "def select_features_chi(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos imprimir los puntajes para cada variable (más grande es mejor), y trazar los puntajes para cada variable como un gráfico de barras para tener una idea de cuántas características debemos seleccionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.472553\n",
      "Feature 1: 0.029193\n",
      "Feature 2: 2.137658\n",
      "Feature 3: 29.381059\n",
      "Feature 4: 8.222601\n",
      "Feature 5: 8.100183\n",
      "Feature 6: 1.273822\n",
      "Feature 7: 0.950682\n",
      "Feature 8: 3.699989\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMaElEQVR4nO3dUYhlhX3H8e+vriGJhmpwKttVO5KKQQquZbCmlpJqUmws1UAoESpSLJuH2GoRytaXptAHC4m2D0XYRJuFWtOgBiWRNGIFCRTbWd3q6iZo7SbZ7eqOpFbbh6ar/z7M2XQyO+Pcnbkzd/673w8Mc++55875c3C+e+bMOU6qCklSPz816QEkSatjwCWpKQMuSU0ZcElqyoBLUlNbNnJj55xzTk1PT2/kJiWpvT179rxeVVOLl29owKenp5mdnd3ITUpSe0m+t9RyT6FIUlMrBjzJe5P8U5J/SfJCkj8dll+Y5OkkLyf5uyTvWf9xJUnHjHIE/j/AVVV1KbAduCbJFcCfA3dX1c8D/wHcvH5jSpIWWzHgNe+/hqenDx8FXAU8OCzfDVy/LhNKkpY00jnwJKcl2QscAR4H/hV4o6qODqscBLYt894dSWaTzM7NzY1jZkkSIwa8qt6uqu3AecDlwIdH3UBV7aqqmaqamZo67ioYSdIqndBVKFX1BvAk8BHgrCTHLkM8Dzg05tkkSe9ilKtQppKcNTx+H/BxYD/zIf/UsNpNwCPrNaQk6Xij3MizFdid5DTmg//Vqvp6kheBryT5M+BZ4N51nFOStMiKAa+q54DLllj+CvPnwyWmd35jQ7d34M5rN3R70mbknZiS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmVgx4kvOTPJnkxSQvJLl1WP65JIeS7B0+PrH+40qSjtkywjpHgdur6pkkHwD2JHl8eO3uqvr8+o0nSVrOigGvqsPA4eHxW0n2A9vWezBJ0rs7oXPgSaaBy4Cnh0W3JHkuyX1Jzh7zbJKkdzFywJOcCTwE3FZVbwL3AB8CtjN/hP6FZd63I8lsktm5ubkxjCxJghEDnuR05uN9f1U9DFBVr1XV21X1DvBF4PKl3ltVu6pqpqpmpqamxjW3JJ3yRrkKJcC9wP6qumvB8q0LVvsksG/840mSljPKVShXAjcCzyfZOyy7A7ghyXaggAPAZ9ZlQknSkka5CuXbQJZ46bHxjyNJGpV3YkpSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLU1IoBT3J+kieTvJjkhSS3Dss/mOTxJC8Nn89e/3ElSceMcgR+FLi9qi4BrgA+m+QSYCfwRFVdBDwxPJckbZAVA15Vh6vqmeHxW8B+YBtwHbB7WG03cP16DSlJOt4JnQNPMg1cBjwNnFtVh4eXXgXOXeY9O5LMJpmdm5tbw6iSpIVGDniSM4GHgNuq6s2Fr1VVAbXU+6pqV1XNVNXM1NTUmoaVJP2/kQKe5HTm431/VT08LH4tydbh9a3AkfUZUZK0lFGuQglwL7C/qu5a8NKjwE3D45uAR8Y/niRpOVtGWOdK4Ebg+SR7h2V3AHcCX01yM/A94LfXZ0RJ0lJWDHhVfRvIMi9fPd5xJEmj8k5MSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUysGPMl9SY4k2bdg2eeSHEqyd/j4xPqOKUlabJQj8C8D1yyx/O6q2j58PDbesSRJK1kx4FX1FPDDDZhFknQC1nIO/JYkzw2nWM5ebqUkO5LMJpmdm5tbw+YkSQutNuD3AB8CtgOHgS8st2JV7aqqmaqamZqaWuXmJEmLrSrgVfVaVb1dVe8AXwQuH+9YkqSVrCrgSbYuePpJYN9y60qS1seWlVZI8gDwUeCcJAeBPwE+mmQ7UMAB4DPrOKMkaQkrBryqblhi8b3rMIsk6QR4J6YkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJampFQOe5L4kR5LsW7Dsg0keT/LS8Pns9R1TkrTYKEfgXwauWbRsJ/BEVV0EPDE8lyRtoBUDXlVPAT9ctPg6YPfweDdw/ZjnkiStYLXnwM+tqsPD41eBc5dbMcmOJLNJZufm5la5OUnSYmv+JWZVFVDv8vquqpqpqpmpqam1bk6SNFhtwF9LshVg+HxkfCNJkkax2oA/Ctw0PL4JeGQ840iSRjXKZYQPAP8IXJzkYJKbgTuBjyd5CfjY8FyStIG2rLRCVd2wzEtXj3kWSdIJ8E5MSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqakVrwOXupne+Y0N29aBO6/dsG1JixlwaZ1s5D8k4D8mpyJPoUhSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlNr+os8SQ4AbwFvA0eramYcQ0mSVjaOP6n2a1X1+hi+jiTpBHgKRZKaWmvAC/hWkj1JdoxjIEnSaNZ6CuVXqupQkp8BHk/ynap6auEKQ9h3AFxwwQVr3Jwk6Zg1HYFX1aHh8xHga8DlS6yzq6pmqmpmampqLZuTJC2w6oAnOSPJB449Bn4d2DeuwSRJ724tp1DOBb6W5NjX+duq+uZYppIkrWjVAa+qV4BLxziLJOkEeBmhJDVlwCWpKQMuSU0ZcElqahz/LxRJamd65zc2dHsH7rx27F/TI3BJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlPeSt/YyXArsKTV8whckpoy4JLUlAGXpKYMuCQ1ZcAlqSmvQpFOARt5xZJXK20cj8AlqSmPwCVtGO9dGC+PwCWpKQMuSU21OYXij16S9JPWdASe5Jok303ycpKd4xpKkrSyVQc8yWnAXwG/AVwC3JDkknENJkl6d2s5Ar8ceLmqXqmqHwFfAa4bz1iSpJWkqlb3xuRTwDVV9XvD8xuBX6qqWxattwPYMTy9GPju6sddlXOA1zd4m5ud++R47pOluV+ON4l98nNVNbV44br/ErOqdgG71ns7y0kyW1Uzk9r+ZuQ+OZ77ZGnul+Ntpn2yllMoh4DzFzw/b1gmSdoAawn4PwMXJbkwyXuATwOPjmcsSdJKVn0KpaqOJrkF+HvgNOC+qnphbJONz8RO32xi7pPjuU+W5n453qbZJ6v+JaYkabK8lV6SmjLgktTUSR1wb/X/SUnOT/JkkheTvJDk1knPtFkkOS3Js0m+PulZNoMkZyV5MMl3kuxP8pFJzzRpSf5w+L7Zl+SBJO+d9EwnbcC91X9JR4Hbq+oS4Args+6TH7sV2D/pITaRvwS+WVUfBi7lFN83SbYBfwDMVNUvMH/hxqcnO9VJHHC81f84VXW4qp4ZHr/F/DfltslONXlJzgOuBb406Vk2gyQ/DfwqcC9AVf2oqt6Y7FSbwhbgfUm2AO8H/n3C85zUAd8G/GDB84MYqx9LMg1cBjw92Uk2hb8A/gh4Z9KDbBIXAnPAXw+nlb6U5IxJDzVJVXUI+DzwfeAw8J9V9a3JTnVyB1zLSHIm8BBwW1W9Oel5JinJbwJHqmrPpGfZRLYAvwjcU1WXAf8NnNK/Q0pyNvM/wV8I/CxwRpLfmexUJ3fAvdV/CUlOZz7e91fVw5OeZxO4EvitJAeYP812VZK/mexIE3cQOFhVx346e5D5oJ/KPgb8W1XNVdX/Ag8DvzzhmU7qgHur/yJJwvx5zf1Vddek59kMquqPq+q8qppm/r+Rf6iqiR9ZTVJVvQr8IMnFw6KrgRcnONJm8H3giiTvH76PrmYT/GK3zZ9UO1GNbvXfSFcCNwLPJ9k7LLujqh6b4EzanH4fuH84+HkF+N0JzzNRVfV0kgeBZ5i/mutZNsEt9d5KL0lNncynUCTppGbAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLU1P8BL2bgFaZcrmoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_fs_chi, X_test_fs_chi, fs_chi = select_features_chi(X_train_enc, y_train_enc, X_test_enc)\n",
    "# Mostramos los scores\n",
    "for i in range(len(fs_chi.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs_chi.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs_chi.scores_))], fs_chi.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que los puntajes son pequeños y es difícil hacerse una idea del número solo sobre qué características son más relevantes. Quizás las características 3, 4, 5 y 8 son las más relevantes.\n",
    "\n",
    "Podríamos establecer k = 4 al configurar `SelectKBest` para seleccionar estas cuatro características principales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a>\n",
    "## <font color=\"#004D7F\"> 4.2. Información Mutua</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información mutua del campo de la teoría de la información es la aplicación de la ganancia de información (típicamente utilizada en la construcción de árboles de decisión) para presentar la selección. La información mutua se calcula entre dos variables y mide la reducción de la incertidumbre para una variable dado un valor conocido de la otra variable.\n",
    "\n",
    "Scikit-learn proporciona una implementación de información mutua para la selección de características a través de la función `mutual_info_classif()`.\n",
    "\n",
    "Al igual que `chi2()`, se puede usar en la estrategia de selección de características `SelectKBest` (y otras estrategias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "Más información en la documentación oficial sobre la función [`mutual_info_classif()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html). \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chi-cuadrado\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# feature selection\n",
    "def select_features_mi(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos realizar la selección de características utilizando información mutua sobre el conjunto de cáncer de mama e imprimir y trazar los puntajes (más grande es mejor) como lo hicimos en la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.058748\n",
      "Feature 1: 0.035770\n",
      "Feature 2: 0.085922\n",
      "Feature 3: 0.090771\n",
      "Feature 4: 0.054822\n",
      "Feature 5: 0.003469\n",
      "Feature 6: 0.000000\n",
      "Feature 7: 0.007673\n",
      "Feature 8: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_fs_mi, X_test_fs_mi, fs_mi = select_features_mi(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs_mi.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs_mi.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs_mi.scores_))], fs_mi.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que algunas de las características tienen una puntuación muy baja, lo que sugiere que tal vez puedan eliminarse. Quizás las características 3, 6, 2 y 5 son las más relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\"> 5. Fase de modelado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas técnicas diferentes para calificar características y seleccionar características basadas en puntajes; ¿Cómo sabes cuál usar? Un enfoque sólido es evaluar modelos utilizando diferentes métodos de selección de características (y número de características) y seleccionar el método que resulte en un modelo con el mejor rendimiento.\n",
    "\n",
    "En esta sección, evaluaremos un modelo de Regresión logística con todas las características en comparación con un modelo construido a partir de características seleccionadas por chi-cuadrado y aquellas características seleccionadas mediante información mutua. La regresión logística es un buen modelo para probar métodos de selección de características, ya que puede funcionar mejor si se eliminan características irrelevantes del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section51\"></a>\n",
    "## <font color=\"#004D7F\"> 5.1. Resultados de linea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es verificar si el modelo mejora realmente con determinadas características seleccionadas. Para ello tenemos que sacar el resultado con todas las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_enc, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_enc)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print(f\"Accuracy: {accuracy*100:,.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section52\"></a>\n",
    "## <font color=\"#004D7F\"> 5.2. Resultados con $\\chi^{2}$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de $\\chi^{2}$ determinamos que había 4 características importantes, por tanto modificaremos la función para seleccionar estas 4 características (`k=4`). Una vez modificadas podemos ver el resultado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.74%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# feature selection\n",
    "def select_features_chi(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k=4) # cambiamos \n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs_chi, X_test_fs_chi = select_features_chi(X_train_enc, y_train_enc, X_test_enc)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs_chi, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat_chi = model.predict(X_test_fs_chi)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat_chi)\n",
    "print(f\"Accuracy: {accuracy*100:,.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos ver que hemos obtenido un rendimiento pero que con las características originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section53\"></a>\n",
    "## <font color=\"#004D7F\"> 5.3. Resultados con Información Mutua</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de Información Mútua también había determinadas 4 características importantes, por tanto modificaremos la función para seleccionar estas 4 características (`k=4`). Una vez modificadas podemos ver el resultado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# feature selection\n",
    "def select_features_mi(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs_mi, X_test_fs_mi = select_features_mi(X_train_enc, y_train_enc, X_test_enc)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs', random_state=7)\n",
    "model.fit(X_train_fs_mi, y_train_enc)\n",
    "# evaluate the model\n",
    "yhat_mi = model.predict(X_test_fs_mi)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test_enc, yhat_mi)\n",
    "print(f\"Accuracy: {accuracy*100:,.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos ver que hemos obtenido un rendimiento mayor que con las características original, aunque al no haber utilizado una validación cruzada si ejecutamos varias veces podemos ver que cambia mucho los valores. Deberemos realizar con un KFold para asegurarnos de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
