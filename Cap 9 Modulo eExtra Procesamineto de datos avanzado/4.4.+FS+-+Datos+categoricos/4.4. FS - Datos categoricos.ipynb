{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 4. Fase de tratamiento de datos</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>4. Feature Selection con datos categóricos</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Librerías](#section11)\n",
    "    * [1.2. Dataset](#section12)\n",
    "    * [1.3. Prepración de datos](#section13)\n",
    "* [2. Codificaicón de variables](#section2)\n",
    "    * [2.1. Codificación ordinal](#section21)\n",
    "    * [2.2. Codifiación de target](#section22)\n",
    "    * [2.3. Codificación del dataset](#section23)\n",
    "* [3. Feature Selection](#section3)\n",
    "    * [3.1. Chi-Cuadrado](#section31)\n",
    "    * [3.2. Información mútua](#section32)\n",
    "* [4. Modelado](#section4)\n",
    "    * [4.1. Resultados de línea base](#section41)\n",
    "    * [4.2. Resultados con Chi-cuadrado](#section42)\n",
    "    * [4.3. Resultados con Información mutua](#section43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, feature selection, también llamado como selección de mejores características o atributos, es el proceso de seleccionar un subconjunto de características pertinentes (variables, predictores) para su uso en construcción de modelos. Las técnicas de feature selection son utilizadas por cuatro razones:\n",
    "* Simplificación de modelos con el fin de hacerlas más sencillas de interpretar para los usuarios/investigadores.\n",
    "* Menor tiempo de entrenamiento.\n",
    "* Evitar la maldición de la dimensionalidad:\n",
    "* Generalización realzada por reducir _overfitting_ (formalmente, reducción de varianza).\n",
    "\n",
    "Los dos métodos de selección de características más utilizados para datos de entrada categóricos cuando la variable objetivo también es categórica (por ejemplo, modelo predictivo de clasificación) son la **estadística de Chi-cuadrado** y la **estadística de información mutua**.\n",
    "\n",
    "Veamos como es para este tipo de datos muy típico en problemas de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último vamos a declarar algunas librerías generales que ya hemos estado trabajando y que usaremos a lo largo de la sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como base de este tutorial, usaremos el llamado \"[Breast Cancer](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer)\". El conjunto de datos clasifica los datos de pacientes con cáncer de mama como una recurrencia o sin recurrencia del cáncer. Hay 286 ejemplos y nueve variables de entrada. Es un problema de clasificación binaria.\n",
    "\n",
    "Un modelo ingenuo puede lograr una precisión del 70% en este conjunto de datos. Una buena puntuación es de aproximadamente 76% +/- 3%. Apuntaremos a esta región, pero tenga en cuenta que los modelos de este tutorial no están optimizados; están diseñados para demostrar esquemas de codificación.\n",
    "\n",
    "Al observar los datos, podemos ver que las nueve variables de entrada son categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    data = pd.read_csv(filename, header=None)\n",
    "    dataset = data.values\n",
    "    X = dataset[:, :-1]\n",
    "    y = dataset[:,-1]\n",
    "    # formateamos todos a str por si alguno lo traduce a numérico automáticamente\n",
    "    X = X.astype(str)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset('data/breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section13\"></a>\n",
    "## <font color=\"#004D7F\"> 1.3. Prepración de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el dataset para entrenamiento validación con un Hold-out del 77%/33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (191, 9) (191,)\n",
      "Test (95, 9) (95,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Codificación de variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar [`OrdinalEncoder()` de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) para codificar cada variable en números enteros. Esta es una clase flexible y permite especificar el orden de las categorías como argumentos si se conoce dicho orden.\n",
    "\n",
    "La mejor práctica al codificar variables es ajustar la codificación en el conjunto de datos de entrenamiento y luego aplicarla a los conjuntos de datos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Codificación ordinal </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función a continuación denominada `prepare_inputs()` toma los datos de entrada para el entrenamiento y validación y los codifica usando una codificación ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Codifiación de target</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos preparar la variable objetivo. Es un problema de clasificación binaria, por lo que necesitamos asignar las dos etiquetas de clase a 0 y 1. Este es un tipo de codificación ordinal, y scikit-learn proporciona la clase [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) diseñada específicamente para este propósito. Podríamos usar `OrdinalEncoder` con la misma facilidad y lograr el mismo resultado, aunque `LabelEncoder` está diseñado para codificar una sola variable.\n",
    "\n",
    "La función `prepare_targets()` entero codifica los datos de salida para el tren y los conjuntos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Codificación del dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, codificamos todo el datset al completo.\n",
    "\n",
    "Una vez codificado todo el dataset podemos realizar Feature Selection a nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  0.  4. ...  0.  3.  0.]\n",
      " [ 1.  2.  9. ...  0.  3.  0.]\n",
      " [ 3.  2. 10. ...  1.  2.  1.]\n",
      " ...\n",
      " [ 4.  0.  1. ...  1.  1.  0.]\n",
      " [ 4.  0.  7. ...  1.  1.  0.]\n",
      " [ 4.  0.  8. ...  0.  0.  0.]]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "\n",
    "print(X_train_enc)\n",
    "print()\n",
    "print(y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Feature Selection </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos técnicas de selección de características populares que se pueden usar para datos de entrada categóricos y una variable de destino categórica (clase).\n",
    "* Estadístico Chi-Cuadrado.\n",
    "* Estadística de información mutua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "## <font color=\"#004D7F\"> 3.1. Chi-Cuadrado </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prueba de hipótesis estadística de chi-cuadrado de Pearson es un ejemplo de una prueba de independencia entre variables categóricas. Los resultados de esta prueba se pueden usar para la selección de características, donde las características que son independientes de la variable de destino se pueden eliminar del conjunto de datos.\n",
    "\n",
    "La librería de scikit-learn proporciona una implementación del test estadístico Chi-cuadrado en la función [`chi2()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html). Esta función se puede utilizar en una estrategia de selección de características, como seleccionar las *k* características más relevantes (valores más grandes) a través de la clase [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) .\n",
    "\n",
    "Por ejemplo, podemos definir la clase `SelectKBest` para usar la función `chi2()` y seleccionar todas las características, luego transformar el tren y los conjuntos de prueba. Posteriormente, imprimimos los puntajes arrojados por el test estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un gráfico de barras de las puntuaciones de importancia de la característica para cada característica. Esto muestra claramente que la característica 3 podría ser la más relevante (según chi-cuadrado) y que quizás cuatro de las nueve características de entrada sean las más relevantes.\n",
    "\n",
    "Podríamos establecer *k = 4* al configurar `SelectKBest` para seleccionar estas cuatro características principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.472553\n",
      "Feature 1: 0.029193\n",
      "Feature 2: 2.137658\n",
      "Feature 3: 29.381059\n",
      "Feature 4: 8.222601\n",
      "Feature 5: 8.100183\n",
      "Feature 6: 1.273822\n",
      "Feature 7: 0.950682\n",
      "Feature 8: 3.699989\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# realizamos FS\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "\n",
    "#Imprimimos los valore y los representamos\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "## <font color=\"#004D7F\"> 3.2. Información mútua </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información mutua del campo de la teoría de la información es la aplicación de la ganancia de información (normalmente utilizada en la construcción de árboles de decisión) a la selección de características. La información mutua se calcula entre dos variables y mide la reducción de la incertidumbre para una variable dado un valor conocido de la otra variable.\n",
    "\n",
    "La libería de scikit-learn proporciona una implementación de información mutua para la selección de características a través de la función [`mutual_info_classif()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html). Al igual que `chi2()`, se puede utilizar en la estrategia de selección de características `SelectKBest` (y otras estrategias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features2(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo, primero se imprimen las puntuaciones calculadas para cada característica de entrada y la variable target. En este caso, podemos ver que algunas de las características tienen una puntuación muy baja, lo que sugiere que quizás se puedan eliminar. Quizás las características 3, 6, 2 y 5 sean las más relevantes.\n",
    "\n",
    "**Nota**: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y compare el resultado promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.000000\n",
      "Feature 1: 0.010636\n",
      "Feature 2: 0.063814\n",
      "Feature 3: 0.041706\n",
      "Feature 4: 0.000000\n",
      "Feature 5: 0.014018\n",
      "Feature 6: 0.030975\n",
      "Feature 7: 0.000000\n",
      "Feature 8: 0.052069\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# realizamos FS\n",
    "X_train_fs, X_test_fs, fs = select_features2(X_train_enc, y_train_enc, X_test_enc)\n",
    "\n",
    "#Imprimimos los valore y los representamos\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Modelado </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez transformado y conocido los resultados de FS, evaluaremos un modelo Logistic Regression (LoR) con todas las características en comparación con un modelo construido a partir de características seleccionadas por chi-cuadrado y esas características seleccionadas a través de información mutua.\n",
    "\n",
    "LoR es un buen modelo para probar métodos de selección de características, ya que puede funcionar mejor si las características irrelevantes se eliminan del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section41\"></a>\n",
    "## <font color=\"#004D7F\"> 4.1. Resultados de línea base </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso, evaluaremos un modelo LogisticRegression utilizando todas las características disponibles. La ejecución del ejemplo imprime el Accuracy del modelo.\n",
    "\n",
    "En este caso, podemos ver que el modelo logra un Accuracy de clasificación de alrededor del 76%. Preferiríamos utilizar un subconjunto de características que logre una precisión de clasificación tan buena o mejor que esta.\n",
    "\n",
    "**Nota**: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y compare el resultado promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_enc, y_train_enc)\n",
    "\n",
    "yhat = model.predict(X_test_enc)\n",
    "\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a>\n",
    "## <font color=\"#004D7F\"> 4.2. Resultados con Chi-cuadrado </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeros vamos a redefinir la función para que pueda escoger las 4 características con el puntaje más alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del ejemplo informa el rendimiento del modelo en solo cuatro de las nueve características de entrada seleccionadas mediante la estadística de chi-cuadrado. En este caso, vemos que el modelo logró una precisión de alrededor del 74%, una ligera caída en el rendimiento.\n",
    "\n",
    "Es posible que algunas de las características eliminadas estén, de hecho, agregando valor directamente o en concierto con las características seleccionadas. En esta etapa, probablemente preferiríamos utilizar todas las funciones de entrada.\n",
    "\n",
    "**Nota**: Los resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y compare el resultado promedio. También puede ser una buena idea explorar el uso de la validación cruzada de k-fold en lugar de una simple división de tren / prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.74\n"
     ]
    }
   ],
   "source": [
    "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)\n",
    "\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section43\"></a>\n",
    "## <font color=\"#004D7F\"> 4.3. Resultados con Información mutua </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeros vamos a redefinir la función para que pueda escoger las 4 características con el puntaje más alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features2(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo, el modelo se ajusta a las cuatro características seleccionadas principales elegidas utilizando información mutua.En este caso, podemos ver un pequeño aumento en la precisión de clasificación al 78%.\n",
    "\n",
    "**Nota**: Los resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y compare el resultado promedio. También puede ser una buena idea explorar el uso de la validación cruzada de k-fold en lugar de una simple división de tren / prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.89\n"
     ]
    }
   ],
   "source": [
    "X_train_fs, X_test_fs = select_features2(X_train_enc, y_train_enc, X_test_enc)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_fs, y_train_enc)\n",
    "\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
