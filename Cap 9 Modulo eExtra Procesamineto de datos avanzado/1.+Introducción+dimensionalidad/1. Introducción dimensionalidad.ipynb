{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo Extra. Preprocesamiento y Tratamiento de datos</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>Reducción de la dimensionalidad de un dataset</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Reducción de dimensionalidad](#section11)\n",
    "* [2. Técnicas para reducción de la dimensionalidad](#section2)\n",
    "    * [2.1. Métodos Selección de Características](#section21)\n",
    "    * [2.2. Factorización de Matrices](#section22)\n",
    "    * [2.3. Aprendizaje Múltiple](#section23)\n",
    "    * [2.4. Métodos de codificador automático (Autoencoders)](#section24)\n",
    "* [3. Conclusiones](#section3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de características de entrada de un conjunto de datos se denomina dimensionalidad. La reducción de dimensionalidad se refiere a técnicas que **reducen** la cantidad de variables en un conjunto de datos.\n",
    "\n",
    "La estadística de alta dimensionalidad y las técnicas de reducción de dimensionalidad se utilizan a menudo para la visualización de datos. \n",
    "\n",
    "Podemos considerar las columnas de datos que representan dimensiones en un espacio de características *n*-dimensional y las filas de datos como puntos en ese espacio. \n",
    "\n",
    "Tener una gran cantidad de dimensiones en el espacio de características puede significar que el volumen de ese espacio es muy grande y, a su vez, los puntos que tenemos en ese espacio (filas de datos) a menudo representan una muestra pequeña y no representativa. Esto puede afectar a nuestra fase de modelado con la llamada \"maldición de la dimensionalidad\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Reducción de dimensionalidad</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La alta dimensionalidad puede significar cientos, miles o incluso millones de variables de entrada.\n",
    "\n",
    "Menos dimensiones de entrada a menudo significan correspondientemente menos parámetros o una estructura más simple en el modelo de ML, lo que se conoce como grados de libertad. Es probable que un modelo con demasiados grados de libertad se adapte demasiado al conjunto de datos de entrenamiento y, por lo tanto, no funcione bien con datos nuevos.\n",
    "\n",
    "Es deseable tener modelos simples que generalicen bien y, a su vez, datos de entrada con pocas variables. Esto es particularmente cierto para los modelos lineales donde el número de entradas y los grados de libertad del modelo a menudo están estrechamente relacionados.\n",
    "\n",
    "**Nota**: Cualquier reducción de dimensionalidad realizada en datos de entrenamiento también debe realizarse en datos nuevos, como un conjunto de datos para test, un conjunto de datos de validación y datos no etiquetados en forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Técnicas para reducción de la dimensionalidad</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cualquier reducción de dimensionalidad realizada en datos de entrenamiento también debe realizarse en datos nuevos, como un conjunto de datos de prueba, un conjunto de datos de validación y datos al hacer una predicción con el modelo final.\n",
    "\n",
    "Veamos algunas de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Métodos Selección de Características</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizás las más comunes son las llamadas técnicas de selección de características que utilizan métodos de puntuación o estadísticos para seleccionar qué características conservar y qué características eliminar.\n",
    "\n",
    "Se tienen dos métodos principales: métodos wrapper y métodos de filtro.\n",
    "\n",
    "* **Métodos Wrapper**: estos métodos envuelven un modelo, ajustando y evaluando el modelo con diferentes subconjuntos de características de entrada y seleccionando el subconjunto que da como resultado el mejor rendimiento del modelo. Eliminación Recursiva de Características (RFE, por sus siglas del inglés) es un ejemplo de un método de selección de características de contenedor.\n",
    "* **Métodos de Filtro**: Utilizan métodos de puntaje, como la correlación entre características y target, para seleccionar un subconjunto de características de entrada que son más predictivas. Los ejemplos incluyen la correlación de Pearson y la prueba de Chi-Cuadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Factorización de Matrices</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden utilizar técnicas de álgebra lineal para la reducción de dimensionalidad. Específicamente, los métodos de factorización de matrices se pueden utilizar para reducir una matriz de conjunto de datos en sus partes constituyentes. \n",
    "\n",
    "Ejemplos incluyen la descomposición propia (*eigendecomposition*) y la descomposición de valores singulares (**SVD**, por sus siglas del inglés).\n",
    "\n",
    "Luego, las partes se pueden clasificar y se puede seleccionar un subconjunto de esas partes que mejor retenga la información del conjunto de datos, es decir, retiene la mayor cantida del dataset original en el dataset reducido.\n",
    "\n",
    "El método más común para clasificar los componentes es el análisis de componentes principales (**PCA**, por sus siglas del inglés)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Aprendizaje Múltiple</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden utilizar técnicas de estadísticas de alta dimensionalidad para la reducción de dimensionalidad. Estas se utilizan para crear una proyección de baja dimensión de datos de alta dimensión, a menudo con el propósito de visualizar datos.\n",
    "\n",
    "La proyección está diseñada tanto para crear una representación de baja dimensión del conjunto de datos como para preservar mejor la estructura, información o las relaciones salientes en los datos.\n",
    "\n",
    "Ejemplos de múltiples técnicas de aprendizaje incluyen:\n",
    "* Kohonen Self-Organizing Map (SOM).\n",
    "* Sammons Mapping\n",
    "* Multidimensional Scaling (MDS)\n",
    "* *t*-distributed Stochastic Neighbor Embedding (*t*-SNE).\n",
    "\n",
    "Las características de la proyección a menudo tienen poca relación con las columnas originales, por ejemplo, no tienen nombres de columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section24\"></a>\n",
    "## <font color=\"#004D7F\"> 2.4. Métodos de codificador automático (*Autoencoders*)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden construir redes neuronales de Deep Learning para realizar una reducción de dimensionalidad.\n",
    "\n",
    "Un enfoque popular se llama codificadores automáticos (*Autoencoders*). Esto implica enmarcar un problema de aprendizaje supervisado donde un modelo debe reproducir la entrada correctamente.\n",
    "\n",
    "Un codificador automático es una especie de red neuronal no supervisada que se utiliza para la reducción de dimensionalidad y el descubrimiento de nuevas características. Más precisamente, un codificador automático es una red neuronal de retroalimentación que está entrenada para predecir la entrada en sí.\n",
    "\n",
    "Después del entrenamiento, el decodificador se descarta y la salida del cuello de botella se usa directamente como la dimensionalidad reducida de la entrada. Las entradas transformadas por este codificador se pueden alimentar a otro modelo, no necesariamente a un modelo de red neuronal.\n",
    "\n",
    "La salida del codificador es un tipo de proyección y, al igual que otros métodos de proyección, no existe una relación directa entre la salida del cuello de botella y las variables de entrada originales, lo que dificulta su interpretación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Conclusiones</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existe la mejor técnica para la reducción de la dimensionalidad. En cambio, el mejor enfoque es utilizar experimentos controlados sistemáticos para descubrir qué técnicas de reducción de dimensionalidad, cuando se combinan con su modelo, dan como resultado el mejor rendimiento en su conjunto de datos.\n",
    "\n",
    "Por lo general, el álgebra lineal y los métodos de aprendizaje múltiple asumen que todas las características de entrada tienen la misma escala o distribución. Esto sugiere que es una buena práctica normalizar o estandarizar los datos antes de usar estos métodos si las variables de entrada tienen diferentes escalas o unidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
