{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo Extra. Preprocesamiento y Tratamiento de datos</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>Desbalanceo de la Clase</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Librerías](#section11)\n",
    "    * [1.2. Conjunto de datos](#section12)\n",
    "* [2. Resultado de Linea Base](#section2)\n",
    "    * [2.1. Procesamiento de datos](#section21)\n",
    "    * [2.2. Evaluación del modelo](#section22)\n",
    "    * [2.3. Resultados del modelo](#section23)\n",
    "* [3. Evaluación de Modelos](#section3)\n",
    "    * [3.1. Evaluación de Modelos probabilísticos](#section31)\n",
    "    * [3.2. Evaluación de LoR equilibrada](#section32)\n",
    "    * [3.3. Evaluación del muestreo de datos con modelos probabilísticos](#section33)\n",
    "* [4. Fase de Forecasting](#section4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas tareas de clasificación desequilibradas requieren un modelo hábil que prediga una etiqueta de clase nítida, donde ambas clases son igualmente importantes. \n",
    "\n",
    "Una forma de evaluar los modelos de clasificación desequilibrados que predicen etiquetas nítidas es calcular la precisión separada en la clase positiva y la clase negativa, lo que se conoce como Sensibilidad y Especificidad. Luego, estas dos medidas se pueden promediar utilizando la media geométrica, denominada `media G`, que es insensible a la distribución de clases sesgada e informa correctamente sobre la habilidad del modelo en ambas clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último vamos a declarar algunas librerías generales que ya hemos estado trabajando y que usaremos a lo largo de la sección. \n",
    "\n",
    "**Nota**: Si es la primera vez que instala `imblear` debera reiniciar Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 246 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /home/manwest/Documentos/Jupyter/enviroment/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/manwest/Documentos/Jupyter/enviroment/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.18.0)\n",
      "Collecting scikit-learn>=0.23\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 542 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/manwest/Documentos/Jupyter/enviroment/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22\n",
      "    Uninstalling scikit-learn-0.22:\n",
      "      Successfully uninstalled scikit-learn-0.22\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections as co\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, utilizaremos un conjunto de datos de aprendizaje automático desequilibrado estándar denominado conjunto de datos de \"derrames de petróleo (oil spill)\", conjunto de datos de \"manchas de petróleo (oil slicks)\" o simplemente \"petróleo (oil)\".\n",
    "\n",
    "El conjunto de datos se desarrolló partiendo de imágenes satelitales del océano, algunas de las cuales contienen un derrame de petróleo y otras no. Las imágenes se dividieron en secciones y se procesaron utilizando algoritmos de visión por computadora para proporcionar un vector de características para describir el contenido de la sección o parche de la imagen.\n",
    "\n",
    "A la tarea se le asigna un vector que describe el contenido de un patch de una imagen de satélite, luego predice si el patch contiene un derrame de petróleo o no, por ejemplo, debido al vertido ilegal o accidental de petróleo en el océano. Hay 937 casos. Cada caso está compuesto por 48 funciones numéricas derivadas de la visión por computadora, un número de parche y una etiqueta de clase.\n",
    "\n",
    "Lo importante de este dataset es el desbalance que existe entre las clases: Hay 896 casos que no existe derrame de petróleo (clase 0) y 41 casos de derrame de petróleo (clase 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "El artículo original se encuentra en la BBDD de [`Springer`](https://link.springer.com/article/10.1023/A:1007452223027).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la primera columna contiene números enteros para el número patch. También podemos ver que las características derivadas de la visión por computadora tienen un valor real con diferentes escalas, como miles en la segunda columna y fracciones en otras columnas. Todas las variables de entrada son numéricas y no se tienen valores NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1        2       3    4           5      6      7        8   \\\n",
       "0      1   2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0   \n",
       "1      2  22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0   \n",
       "2      3    115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0   \n",
       "3      4   1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0   \n",
       "4      5    312   950.27  440.86   37    780000.0  41.43   7.03   3350.0   \n",
       "..   ...    ...      ...     ...  ...         ...    ...    ...      ...   \n",
       "932  200     12    92.42  364.42  135     97200.0  59.42  10.34    884.0   \n",
       "933  201     11    98.82  248.64  159     89100.0  59.64  10.18    831.0   \n",
       "934  202     14    25.14  428.86   24    113400.0  60.14  17.94    847.0   \n",
       "935  203     10    96.00  451.30   68     81000.0  59.90  15.01    831.0   \n",
       "936  204     11     7.73  235.73  135     89100.0  61.82  12.24    831.0   \n",
       "\n",
       "       9   ...       40        41       42       43     44  45        46  \\\n",
       "0    0.19  ...  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    0.02  ...  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2    0.18  ...  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    0.19  ...  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    0.17  ...  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..    ...  ...      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  0.17  ...   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  0.17  ...   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  0.30  ...   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935  0.25  ...   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  0.20  ...   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "        47    48  49  \n",
       "0    65.74  7.95   1  \n",
       "1    65.73  6.26   0  \n",
       "2    65.81  7.84   1  \n",
       "3    65.67  8.07   1  \n",
       "4    65.66  7.35   0  \n",
       "..     ...   ...  ..  \n",
       "932  65.85  6.39   0  \n",
       "933  65.70  6.53   0  \n",
       "934  65.91  6.12   0  \n",
       "935  65.97  6.32   0  \n",
       "936  65.65  6.26   0  \n",
       "\n",
       "[937 rows x 50 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/oil-spill.csv'\n",
    "dataframe = pd.read_csv(filename, header=None)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echamos un vistazo a las características del dataset y verificamos el desbalance entre clases que se tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    896\n",
       "1.0     41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe.shape)\n",
    "\n",
    "target = dataframe.values[:,-1]\n",
    "dataframe.groupby(target).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Resultado de Linea Base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio se evaluarán los modelos candidatos utilizando una validación cruzada estratificada con repetición de *k*-fold (`RepeatedStratifiedKFold`). Usaremos *k = 10*, lo que significa que cada pliegue contendrá aproximadamente 937/10 o aproximadamente 94 ejemplos.\n",
    "\n",
    "La **validación cruzada estratificada** significa que cada *fold* contendrá la misma mezcla de ejemplos por clase, es decir, entre 96% y 4% de cada calase. **Repetir** significa que el proceso de evaluación se realizará varias veces para ayudar a evitar resultados fortuitos y capturar mejor la varianza del modelo elegido. Usaremos 3 repeticiones.\n",
    "\n",
    "Recuerde que la sensibilidad es una medida de la precisión de la clase positiva y la especificidad es una medida de la precisión de la clase negativa.\n",
    "* Sensibilidad = TruePositives / (TruePositives + FalseNegatives)\n",
    "* Especificidad = TrueNegatives / (TrueNegatives + FalsePositives)\n",
    "\n",
    "G-Mean, función [`geometric_mean_score()`](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.metrics.geometric_mean_score.html) de Scikit-Learn, busca un equilibrio de estos puntajes, la media geométrica, donde un desempeño pobre para uno u otro da como resultado un puntaje promedio G bajo.\n",
    "* G-Mean = sqrt (Sensibilidad * Especificidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Procesamiento de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, podemos definir una función para cargar el conjunto de datos y dividir las columnas en variables de entrada y salida. También eliminaremos la columna 22 porque la columna contiene un solo valor y la primera columna que define el número patch de imagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "def load_dataset(data):\n",
    "    # Eliminar Columnas\n",
    "    data.drop(22, axis=1, inplace=True)\n",
    "    data.drop(0, axis=1, inplace=True)\n",
    "    # convertir a NumPy array\n",
    "    data = data.values\n",
    "    # Dividir input output\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    # Codificar el target en 0 o 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Evaluación del modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se define una función que evaluará un modelo dado en el conjunto de datos y devolverá una lista de puntuaciones G-Mean para cada fold y repetición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # Métrica de evaluación\n",
    "    metric = make_scorer(geometric_mean_score)\n",
    "    # Evaluación del modelo\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Resultados del modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo que predice la etiqueta de clase mayoritaria (0) o la etiqueta de clase minoritaria (1) para todos los casos dará como resultado una G-Mean de cero. Como tal, una buena estrategia predeterminada sería predecir al azar una etiqueta de clase u otra con una probabilidad del 50% y apuntar a una G-Mean de aproximadamente 0,5.\n",
    "\n",
    "Esto se puede lograr usando la clase [`DummyClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) y estableciendo el argumento `strategy` en `uniform`.\n",
    "\n",
    "Una vez que se evalúa el modelo, podemos informar la media y la desviación estándar de las puntuaciones medias G directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 47) (937,) Counter({0: 896, 1: 41})\n",
      "Mean G-Mean: 0.516 (0.131)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset(dataframe)\n",
    "print(X.shape, y.shape, co.Counter(y))\n",
    "# Definir el modelo\n",
    "model = DummyClassifier(strategy='uniform')\n",
    "# Evaluacion del modelo\n",
    "scores = evaluate_model(X, y, model)\n",
    "print('Mean G-Mean: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que el algoritmo de la línea de base alcanza un G-Mean de 0.51, superando por poco el máximo teórico de 0,5. Esta puntuación proporciona un límite inferior en la habilidad del modelo; cualquier modelo que alcance un promedio G-Mean por encima de aproximadamente 0,51 tiene habilidad, mientras que los modelos que logran una puntuación por debajo de este valor no tienen habilidad.\n",
    "\n",
    "Es interesante notar que un buen G-MEan reportado en el documento fue de aproximadamente 0,811, aunque el procedimiento de evaluación del modelo fue diferente. Esto proporciona un objetivo aproximado para un \"buen\" rendimiento en este conjunto de datos.\n",
    "\n",
    "Ahora que tenemos un arnés de prueba y una línea de base en el rendimiento, podemos comenzar a evaluar algunos modelos en este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Evaluación de Modelos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, evaluaremos un conjunto de diferentes técnicas en el conjunto de datos utilizando el arnés de prueba desarrollado en la sección anterior.\n",
    "\n",
    "El objetivo es tanto demostrar cómo resolver el problema de manera sistemática como demostrar la capacidad de algunas técnicas diseñadas para problemas de clasificación desequilibrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "## <font color=\"#004D7F\"> 3.1. Evaluación de Modelos probabilísticos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos probabilísticos son aquellos que se ajustan a los datos en un marco probabilístico y, en general, funcionan bien en conjuntos de datos de clasificación desequilibrados. Evaluaremos los siguientes modelos probabilísticos con hiperparámetros predeterminados en el conjunto de datos:\n",
    "\n",
    "* Logistic Regression (LoR)\n",
    "* Linear Discriminant Analysis (LDA)\n",
    "* Gaussian Naive Bayes (NB)\n",
    "\n",
    "Tanto LR como LDA son sensibles a la escala de las variables de entrada y, a menudo, esperan y/o funcionan mejor si las variables de entrada con diferentes escalas se normalizan o estandarizan como un paso previo al procesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.672 (0.203)\n",
      ">LDA 0.755 (0.147)\n",
      ">NB 0.707 (0.202)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models, names, results = list(), list(), list()\n",
    "# LoR\n",
    "models.append(Pipeline(steps=[('t', StandardScaler()),('m',LogisticRegression(solver='liblinear'))]))\n",
    "names.append('LR')\n",
    "# LDA\n",
    "models.append(Pipeline(steps=[('t', StandardScaler()),('m',LinearDiscriminantAnalysis())]))\n",
    "names.append('LDA')\n",
    "# NB\n",
    "models.append(GaussianNB())\n",
    "names.append('NB')\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for i in range(len(models)):\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que cada algoritmo tiene habilidad, logrando una media G-Mean superior a 0,5. Los resultados sugieren que un LDA podría ser el mejor rendimiento de los modelos probados.\n",
    "\n",
    "En la Figura podemos ver que la distribución tanto para LDA como para NB es compacta y hábil y que el LoR puede tener algunos resultados durante la ejecución en los que el método funcionó mal, empujando la distribución hacia abajo.\n",
    "\n",
    "Esto resalta que no es solo el desempeño medio, sino también la consistencia del modelo lo que debe tenerse en cuenta al seleccionar un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "## <font color=\"#004D7F\"> 3.2. Evaluación de LoR equilibrada</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de LoR admite una modificación que ajusta la importancia de los errores de clasificación para que sean inversamente proporcionales a la ponderación de la clase. Esto permite que el modelo aprenda mejor el límite de la clase a favor de la clase minoritaria, lo que podría ayudar al rendimiento G-MEan general. Podemos lograr esto estableciendo el argumento `class_weight = 'balanced'`.\n",
    "\n",
    "Además, LoR es sensible a la escala de las variables de entrada y puede funcionar mejor con entradas normalizadas o estandarizadas; como tal, es una buena idea probar ambos para un conjunto de datos determinado. Además, se puede usar una distribución de potencia para extender la distribución de cada variable de entrada y hacer que las variables con una distribución similar a la de Gauss sean más gaussianas. Esto puede beneficiar a modelos como LoR que hacen suposiciones sobre la distribución de variables de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Balanced 0.848 (0.115)\n",
      ">Balanced-Norm 0.836 (0.088)\n",
      ">Balanced-Std 0.834 (0.129)\n",
      ">Balanced-Power 0.862 (0.124)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models, names, results = list(), list(), list()\n",
    "# LoR Balanced\n",
    "models.append(LogisticRegression(solver='liblinear', class_weight='balanced'))\n",
    "names.append('Balanced')\n",
    "# LoR Balanced + Normalization\n",
    "models.append(Pipeline(steps=[('t', MinMaxScaler()),('m', LogisticRegression(solver='liblinear', class_weight='balanced'))]))\n",
    "names.append('Balanced-Norm')\n",
    "# LoR Balanced + Standardization\n",
    "models.append(Pipeline(steps=[('t', StandardScaler()),('m', LogisticRegression(solver='liblinear', class_weight='balanced'))]))\n",
    "names.append('Balanced-Std')\n",
    "# LoR Balanced  + Transform\n",
    "models.append(Pipeline(steps=[('t1', MinMaxScaler()), ('t2', PowerTransformer()),('m', LogisticRegression(solver='liblinear', class_weight='balanced'))]))\n",
    "names.append('Balanced-Power')\n",
    "\n",
    "# Evaluar cada model\n",
    "for i in range(len(models)):\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que la versión balanceada de regresión logística funciona mucho mejor que todos los modelos probabilísticos evaluados en la sección anterior.\n",
    "\n",
    "Los resultados sugieren que quizás el uso de LoR equilibrado con normalización de datos para el preprocesamiento rinde mejor en este conjunto de datos con una puntuación G-Mean media de aproximadamente 0,848 y con transformación 0,862, llegando, como muestra la Figura, a casi 1. Esto está en el rango o mejor que los resultados reportados en el artículo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section33\"></a>\n",
    "## <font color=\"#004D7F\"> 3.3. Evaluación el muestreo de datos con modelos probabilísticos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El muestreo de datos proporciona una forma de preparar mejor el conjunto de datos de entrenamiento desequilibrado antes de ajustar un modelo.\n",
    "\n",
    "Quizás el muestreo de datos más popular es la técnica de sobremuestreo [`SMOTE`](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html) para crear nuevos ejemplos sintéticos para la clase minoritaria. Esto se puede combinar con el algoritmo del [Vecino Más Cercano Editado (ENN)](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.EditedNearestNeighbours.html) que ubicará y eliminará ejemplos del conjunto de datos que sean ambiguos, lo que facilitará que los modelos aprendan a discriminar entre las dos clases. Esta combinación se llama SMOTE-ENN y se puede implementar usando la clase [`SMOTEENN`](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.combine.SMOTEENN.html) de la librería imabalanced-learn.\n",
    "\n",
    "SMOTE y ENN funcionan mejor cuando los datos de entrada se escalan de antemano. Esto se debe a que ambas técnicas implican el uso interno del algoritmo de vecino más cercano y este algoritmo es sensible a las variables de entrada con diferentes escalas. Compararemos cuatro variaciones del modelo de regresión logística con muestreo de datos, específicamente:\n",
    "* SMOTEENN + LR\n",
    "* Normalización + SMOTEENN + LR\n",
    "* Estandarización + SMOTEENN + LR\n",
    "* Normalización + Transormación + SMOTEENN + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.865 (0.093)\n",
      ">Norm 0.825 (0.114)\n",
      ">Std 0.817 (0.147)\n",
      ">Power 0.883 (0.121)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models, names, results = list(), list(), list()\n",
    "# SMOTEENN\n",
    "models.append(Pipeline(steps=[('e', SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))), ('m', LogisticRegression(solver='liblinear'))]))\n",
    "names.append('LR')\n",
    "# SMOTEENN + Norm\n",
    "models.append(Pipeline(steps=[('t', MinMaxScaler()), ('e', SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))), ('m', LogisticRegression(solver='liblinear'))]))\n",
    "names.append('Norm')\n",
    "# SMOTEENN + Std\n",
    "models.append(Pipeline(steps=[('t', StandardScaler()), ('e', SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))), ('m', LogisticRegression(solver='liblinear'))]))\n",
    "names.append('Std')\n",
    "# SMOTEENN + Power\n",
    "models.append(Pipeline(steps=[('t1', MinMaxScaler()), ('t2', PowerTransformer()), ('e', SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))), ('m', LogisticRegression(solver='liblinear'))]))\n",
    "names.append('Power')\n",
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "    results.append(scores)\n",
    "\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que la adición de SMOTEENN mejora el rendimiento del algoritmo LoR predeterminado, logrando una media G-Mean de 0,865. Esto es incluso mejor que el LoR equilibrado sin ningún escalado de datos (sección anterior) que logró una G-Mean de aproximadamente 0,878.\n",
    "\n",
    "Los resultados sugieren que quizás la combinación final de normalización, transformación de potencia y estandarización logre una puntuación ligeramente mejor que la LoR predeterminada con SMOTEENN con una G-Mean de aproximadamente 0,873."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Fase de Forecasting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de SMOTEENN con Regresión logística directamente sin ningún escalado de datos probablemente proporciona el modelo más simple y de mejor rendimiento que podría usarse en el futuro.\n",
    "\n",
    "Primero, podemos definir el modelo como una tubería. Una vez definido, podemos ajustarlo a todo el conjunto de datos de entrenamiento. Una vez que se ajusta, podemos usarlo para hacer predicciones de nuevos datos llamando a la función `predict()`. Esto devolverá la etiqueta de clase de 0 para ningún derrame de petróleo o 1 para un derrame de petróleo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Spill Cases:\n",
      ">Predecido=0 (esperado 0)\n",
      ">Predecido=0 (esperado 0)\n",
      ">Predecido=0 (esperado 0)\n",
      "Spill Cases:\n",
      ">Predecido=1 (esperado 1)\n",
      ">Predecido=1 (esperado 1)\n",
      ">Predecido=1 (esperado 1)\n"
     ]
    }
   ],
   "source": [
    "# Los nuevos datos tienen todas las características\n",
    "def load_dataset(filename):\n",
    "    data = pd.read_csv(filename, header=None)\n",
    "    data = data.values\n",
    "    X, y = data[:, 1:-1], data[:, -1]\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X, y\n",
    "\n",
    "X, y = load_dataset(filename)\n",
    "\n",
    "# Definición del modelo\n",
    "smoteenn = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "pipeline = Pipeline(steps=[('e', smoteenn), ('m', model)])\n",
    "# Ajuste del modelo\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Evaluación con la clase 0\n",
    "print('Non-Spill Cases:')\n",
    "data = [[329,1627.54,1409.43,51,822500,35,6.1,4610,0.17,178.4,0.2,0.24,0.39,0.12,0.27,138.32,34.81,2.02,0.14,0.19,75.26,0,0.47,351.67,0.18,9.24,0.38,2.57,-2.96,-0.28,1.93,0,1.93,34,1710,0,25.84,78,55,1460.31,710.63,451.78,150.85,3.23,0,4530.75,66.25,7.85],\n",
    "        [3234,1091.56,1357.96,32,8085000,40.08,8.98,25450,0.22,317.7,0.18,0.2,0.49,0.09,0.41,114.69,41.87,2.31,0.15,0.18,75.26,0,0.53,351.67,0.18,9.24,0.24,3.56,-3.09,-0.31,2.17,0,2.17,281,14490,0,80.11,78,55,4287.77,3095.56,1937.42,773.69,2.21,0,4927.51,66.15,7.24],\n",
    "        [2339,1537.68,1633.02,45,5847500,38.13,9.29,22110,0.24,264.5,0.21,0.26,0.79,0.08,0.71,89.49,32.23,2.2,0.17,0.22,75.26,0,0.51,351.67,0.18,9.24,0.27,4.21,-2.84,-0.29,2.16,0,2.16,228,12150,0,83.6,78,55,3959.8,2404.16,1530.38,659.67,2.59,0,4732.04,66.34,7.67]]\n",
    "\n",
    "#Hacer predicciones\n",
    "for row in data:\n",
    "    yhat = pipeline.predict([row])\n",
    "    label = yhat[0]\n",
    "    print('>Predecido=%d (esperado 0)' % (label))\n",
    "\n",
    "# Evaluación con la clase 1\n",
    "print('Spill Cases:')\n",
    "data = [[2971,1020.91,630.8,59,7427500,32.76,10.48,17380,0.32,427.4,0.22,0.29,0.5,0.08,0.42,149.87,50.99,1.89,0.14,0.18,75.26,0,0.44,351.67,0.18,9.24,2.5,10.63,-3.07,-0.28,2.18,0,2.18,164,8730,0,40.67,78,55,5650.88,1749.29,1245.07,348.7,4.54,0,25579.34,65.78,7.41],\n",
    "    [3155,1118.08,469.39,11,7887500,30.41,7.99,15880,0.26,496.7,0.2,0.26,0.69,0.11,0.58,118.11,43.96,1.76,0.15,0.18,75.26,0,0.4,351.67,0.18,9.24,0.78,8.68,-3.19,-0.33,2.19,0,2.19,150,8100,0,31.97,78,55,3471.31,3059.41,2043.9,477.23,1.7,0,28172.07,65.72,7.58],\n",
    "    [115,1449.85,608.43,88,287500,40.42,7.34,3340,0.18,86.1,0.21,0.32,0.5,0.17,0.34,71.2,16.73,1.82,0.19,0.29,87.65,0,0.46,132.78,-0.01,3.78,0.7,4.79,-3.36,-0.23,1.95,0,1.95,29,1530,0.01,38.8,89,69,1400,250,150,45.13,9.33,1,31692.84,65.81,7.84]]\n",
    "\n",
    "#Hacer las predicciones\n",
    "for row in data:\n",
    "    yhat = pipeline.predict([row])\n",
    "    label = yhat[0]\n",
    "    print('>Predecido=%d (esperado 1)' % (label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo, primero se ajusta el modelo a todo el conjunto de datos de entrenamiento.\n",
    "\n",
    "Luego, el modelo de ajuste utilizado para predecir la etiqueta de un derrame de petróleo para los casos en los que sabemos que no hay ninguno, elegido del archivo del conjunto de datos. Podemos ver que todos los casos están correctamente predichos.\n",
    "\n",
    "Luego, algunos casos de derrames de petróleo reales se utilizan como entrada para el modelo y se predice la etiqueta. Como podríamos haber esperado, se vuelven a predecir las etiquetas correctas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
