{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 5. Fase de modelado</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>4. Super (lerner)estimadores en Algoritmos ensamblados</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Librerías](#section11)\n",
    "    * [1.2. CSV](#section12)\n",
    "* [2. Super-Estimado en Scikit-learn](#section2)\n",
    "    * [2.1. Crear lista de modelos](#section21)\n",
    "    * [2.2. Validación cruzada del Super-Estimador](#section22)\n",
    "    * [2.3. Evaluación del modelo](#section23)\n",
    "    * [2.4. Hacer predicciones](#section24)\n",
    "* [3. Conclusiones](#section3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eel20\\AppData\\Local\\Temp\\ipykernel_16620\\1126351303.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema principal que tenemos como científico de datos es verificar qué modelo es el que mejor comportamiento tiene en nuestro conjunto de datos. Para ello, lo único que nos queda es utilizar la experimentación empírica para probar y descubrir qué modelo de los muchos que hay con diferentes hiperparámetros funciona mejor para su conjunto de datos.\n",
    "\n",
    "Tenga en cuenta que ya ha ajustado muchos algoritmos diferentes en su conjunto de datos, y algunos algoritmos han sido evaluados muchas veces con diferentes configuraciones. Es posible que tenga muchas decenas o cientos de modelos diferentes de su problema. ¿Por qué no usar todos esos modelos en lugar del mejor modelo del grupo? Esta es la intuición detrás del llamado algoritmo de conjunto ''Súper-Estimador''."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a declarar algunas librerías generales que ya hemos estado trabajando y que usaremos a lo largo de la sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from math import sqrt\n",
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "#from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. CSV</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección, vamos a utilizar un problema de regresión. Para ello utilizaremos el dataset Boston House Price. Este es un problema de regresión donde todos los atributos son numéricos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df_reg = pd.read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = df_reg.values\n",
    "X = array[:,0:13]\n",
    "y = array[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiremos los datos para que el 50 por ciento se use para entrenar el modelo y el 50 por ciento se retenga para evaluar el supermodelo final y los modelos base. Fijarse que tenemos 253 por parte de Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (253, 13) (253,) Test (253, 13) (253,)\n"
     ]
    }
   ],
   "source": [
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.50)\n",
    "print('Train', X.shape, y.shape, 'Test', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Super-Lerner(Estimado)en Scikit-learn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Crear lista de modelos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definiremos un conjunto de modelos de regresión diferentes.\n",
    "\n",
    "La función `get_models()` a continuación define todos los modelos y los devuelve como una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista con los modelos base\n",
    "def get_models():\n",
    "    models=list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet())\n",
    "    models.append(SVR(gamma='scale'))\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(KNeighborsRegressor())\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Validación cruzada del Super-Estimador</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema utilizaremos un k-fold de 10 particiones. Para cada fold, ajustaremos el modelo en la parte de entrenamiento y haremos predicciones fuera del fold en la parte de validación. Esto se repite para cada modelo y se almacenan todas las predicciones fuera del fold.\n",
    "\n",
    "Cada predicción fuera del fold será una columna para la entrada del metamodelo. Recopilaremos columnas de cada algoritmo para un fold de los datos, apilando horizontalmente las filas. Luego, para todos los grupos de columnas que recopilamos, apilaremos verticalmente estas filas en un conjunto de datos largo con 253 filas y nueve columnas.\n",
    "\n",
    "El siguietne Código define la función `get_out_of_fold_predictions()` para un conjunto de datos de Train y una lista de modelos; devolverá el conjunto de datos de entrada y salida necesarios para entrenar el metamodelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    #Definir del k-fold\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # Enumeramos las particiones\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        #obtenemos los datos\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        #Ajustes y predicciones de cada submodelo\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            #Almacenamiento de cada dcolumna\n",
    "            fold_yhats.append(yhat.reshape(len(yhat), 1))\n",
    "        #Almacenar el fold e yhats como columnas\n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "Documentación oficial de la clase [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Evaluación del modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section231\"></a>\n",
    "### <font color=\"#004D7F\"> 2.3.1. Preparar el conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces podemos llamar a la función para obtener los modelos y la función para preparar el conjunto de datos del metamodelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get models\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X, y, models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section232\"></a>\n",
    "### <font color=\"#004D7F\"> 2.3.2. Ajuste de los modelos base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos ajustar todos los modelos base en todo el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section233\"></a>\n",
    "### <font color=\"#004D7F\"> 2.3.3. Ajuste del Meta-modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, podemos ajustar el metamodelo en el conjunto de datos de entrenamiento. En este caso, utilizaremos un modelo de regresión lineal como metamodelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model =LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section234\"></a>\n",
    "### <font color=\"#004D7F\"> 2.3.4. Evaluación de los modelos base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos evaluar los modelos base en el conjunto de datos de reserva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate a list of models on a dataset\n",
    "def  evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section24\"></a>\n",
    "## <font color=\"#004D7F\"> 2.4. Hacer predicciones</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, usaremos el Super-Estimador (base y metamodelo) para hacer predicciones sobre el conjunto de datos y evaluar el rendimiento del enfoque.\n",
    "\n",
    "La función `super_learner_predictions()` utilizará el metamodelo para hacer predicciones para nuevos datos. Podemos llamar a esta función y evaluar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with stacked model\n",
    "def super_lerner_prediction(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = hstack(meta_X)\n",
    "    return meta_model.predict(meta_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos evaluar esta función y evaluar el modelo. Para ello terminamos de insertar el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE 4.669\n",
      "ElasticNet: RMSE 5.050\n",
      "SVR: RMSE 8.356\n",
      "DecisionTreeRegressor: RMSE 4.497\n",
      "KNeighborsRegressor: RMSE 6.782\n",
      "AdaBoostRegressor: RMSE 3.780\n",
      "BaggingRegressor: RMSE 3.630\n",
      "RandomForestRegressor: RMSE 3.627\n",
      "ExtraTreesRegressor: RMSE 3.439\n",
      "Super Lerner: RMSE 3.564\n"
     ]
    }
   ],
   "source": [
    "##ya se hizo\n",
    "\n",
    "## get models\n",
    "#models = get_models()\n",
    "## get out of fold predictions\n",
    "#meta_X, meta_y = get_out_of_fold_predictions(X, y, models)\n",
    "\n",
    "##hasta aqui \n",
    "\n",
    "# fit base models\n",
    "fit_base_models(X, y, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(X_val, y_val, models)\n",
    "# evaluate meta model\n",
    "yhat = super_lerner_prediction(X_val, models, meta_model)\n",
    "print('Super Lerner: RMSE %.3f' % (sqrt(mean_squared_error(y_val, yhat))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Conclusiones</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo, primero se informa la forma del conjunto de datos preparado, luego la forma del conjunto de datos para el metamodelo.\n",
    "\n",
    "A continuación, el rendimiento de cada modelo base se informa en el conjunto de datos de espera y, finalmente, el rendimiento del Súper-Estimador en el conjunto de datos de espera.\n",
    "\n",
    "Sus resultados específicos serán diferentes dada la naturaleza estocástica del conjunto de datos y los algoritmos de aprendizaje. Intenta ejecutar el ejemplo varias veces.\n",
    "\n",
    "En este caso, podemos ver que los modelos de conjunto funcionan bien en el conjunto de datos y los algoritmos lineales y no lineales no tan bien.\n",
    "\n",
    "También podemos ver que el Súper-Estimador superó a todos los modelos base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
